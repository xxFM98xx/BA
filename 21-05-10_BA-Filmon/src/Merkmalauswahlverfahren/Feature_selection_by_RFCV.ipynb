{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here you must specify your own path\n",
    "root = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dic to get the respective target values of the numbers.\n",
    "target_dic = {\n",
    "    0: '(0, 20]constant',\n",
    "    1: '(20, 40]constant',\n",
    "    2: '(40, 60]constant',\n",
    "    3: '(60, 80]constant',\n",
    "    4: '(80, 100]constant',\n",
    "    5: '(0, 20]intermittent',\n",
    "    6: '(20, 40]intermittent',\n",
    "    7: '(40, 60]intermittent',\n",
    "    8: '(60, 80]intermittent',\n",
    "    9: '(80, 100]intermittent',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in csv file into dataframe\n",
    "df_train = pd.read_csv(root + 'data/02_processed/train.csv', sep=';')\n",
    "df_train.pop('Unnamed: 0')\n",
    "\n",
    "df2=df_train.copy()\n",
    "df2.drop(['target','4','66','67'], axis = 1,inplace=True)\n",
    "\n",
    "\n",
    "#read validation and test data from csv\n",
    "df_validation = pd.read_csv(root + 'data/02_processed/validation.csv', sep=';')\n",
    "df_validation.set_index('user_id',inplace=True)\n",
    "df_test = pd.read_csv(root + 'data/02_processed/test.csv', sep=';')\n",
    "df_test.set_index('user_id',inplace=True)\n",
    "\n",
    "#encode target column of test data\n",
    "target_test=pd.get_dummies(df_test['target'], prefix='target')\n",
    "\n",
    "#at the end, the 3 data frames will be written into several CSV.\n",
    "completed_train=df_train.copy()\n",
    "completed_test=df_test.copy()\n",
    "completed_validation=df_validation.copy()\n",
    "\n",
    "# target of train data without encoding\n",
    "target_train= df_train['target']\n",
    "\n",
    "#delete target from training data\n",
    "df_train.pop('target')\n",
    "\n",
    "# target of test data without encoding\n",
    "target_test= df_test['target']\n",
    "\n",
    "#delete target from test data\n",
    "df_test.pop('target')\n",
    "\n",
    "#Will be used for training the RFECV.\n",
    "train=df_train.copy()\n",
    "\n",
    "\n",
    "\n",
    "train2=df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5_Female</th>\n",
       "      <th>5_Male</th>\n",
       "      <th>6_Both Sides</th>\n",
       "      <th>6_Left</th>\n",
       "      <th>6_Right</th>\n",
       "      <th>8_No</th>\n",
       "      <th>8_children</th>\n",
       "      <th>8_parents</th>\n",
       "      <th>8_parents|children</th>\n",
       "      <th>8_parents|siblings</th>\n",
       "      <th>...</th>\n",
       "      <th>82_YES</th>\n",
       "      <th>83_NO</th>\n",
       "      <th>83_YES</th>\n",
       "      <th>84_NO</th>\n",
       "      <th>84_YES</th>\n",
       "      <th>85_NO</th>\n",
       "      <th>85_YES</th>\n",
       "      <th>4</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.761029</td>\n",
       "      <td>0.544118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.296703</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.329670</td>\n",
       "      <td>0.533088</td>\n",
       "      <td>0.591912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.670330</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3168</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3169</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.516484</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3170 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      5_Female  5_Male  6_Both Sides  6_Left  6_Right  8_No  8_children  \\\n",
       "0            1       0             0       0        1     0           0   \n",
       "1            1       0             0       0        1     1           0   \n",
       "2            1       0             1       0        0     1           0   \n",
       "3            1       0             0       0        1     0           0   \n",
       "4            1       0             0       0        1     0           0   \n",
       "...        ...     ...           ...     ...      ...   ...         ...   \n",
       "3165         1       0             0       0        1     1           0   \n",
       "3166         1       0             0       0        1     1           0   \n",
       "3167         1       0             0       0        1     1           0   \n",
       "3168         1       0             0       1        0     1           0   \n",
       "3169         1       0             0       0        1     1           0   \n",
       "\n",
       "      8_parents  8_parents|children  8_parents|siblings  ...  82_YES  83_NO  \\\n",
       "0             1                   0                   0  ...       0      1   \n",
       "1             0                   0                   0  ...       0      1   \n",
       "2             0                   0                   0  ...       1      1   \n",
       "3             1                   0                   0  ...       1      1   \n",
       "4             1                   0                   0  ...       0      1   \n",
       "...         ...                 ...                 ...  ...     ...    ...   \n",
       "3165          0                   0                   0  ...       0      0   \n",
       "3166          0                   0                   0  ...       0      0   \n",
       "3167          0                   0                   0  ...       0      0   \n",
       "3168          0                   0                   0  ...       0      0   \n",
       "3169          0                   0                   0  ...       0      1   \n",
       "\n",
       "      83_YES  84_NO  84_YES  85_NO  85_YES         4        66        67  \n",
       "0          0      1       0      0       1  0.230769  0.761029  0.544118  \n",
       "1          0      1       0      1       0  0.296703  0.170000  0.060000  \n",
       "2          0      1       0      1       0  0.428571  0.920000  0.890000  \n",
       "3          0      1       0      1       0  0.329670  0.533088  0.591912  \n",
       "4          0      1       0      1       0  0.670330  0.560000  0.540000  \n",
       "...      ...    ...     ...    ...     ...       ...       ...       ...  \n",
       "3165       1      1       0      1       0  0.692308  0.330000  0.130000  \n",
       "3166       1      1       0      1       0  0.692308  0.330000  0.130000  \n",
       "3167       1      1       0      1       0  0.692308  0.330000  0.130000  \n",
       "3168       1      1       0      1       0  0.527473  0.900000  0.940000  \n",
       "3169       0      0       1      1       0  0.516484  0.820000  0.800000  \n",
       "\n",
       "[3170 rows x 89 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract numeric columns and encode categorical columns with  one hot encoding.\n",
    "toOneHot = OneHotEncoder(handle_unknown='ignore')\n",
    "categorical = [df2.columns]\n",
    "categorical\n",
    "column_4 =train2['4']\n",
    "column_66 =train2['66']\n",
    "column_67 =train2['67']\n",
    "\n",
    "for index in categorical:\n",
    "    train2= pd.get_dummies(train[index],prefix=index)\n",
    "    \n",
    "    \n",
    "train2['4']=column_4\n",
    "train2['66']=column_66\n",
    "train2['67']=column_67\n",
    "\n",
    "train2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical coumn names\n",
    "categorical_columns = ['5', '6', '8', '10', '11', '13', '35', '37', '40',\n",
    "       '65', '68', '69', '70', '71', '72', '73', '74', '76', '77', '78', '79',\n",
    "       '80', '81', '82', '83', '84', '85']\n",
    "        \n",
    "#numeric column names\n",
    "numerical_columns = ['4','66','67']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocess',\n",
       "                 ColumnTransformer(transformers=[('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['5', '6', '8', '10', '11',\n",
       "                                                   '13', '35', '37', '40', '65',\n",
       "                                                   '68', '69', '70', '71', '72',\n",
       "                                                   '73', '74', '76', '77', '78',\n",
       "                                                   '79', '80', '81', '82', '83',\n",
       "                                                   '84', '85']),\n",
       "                                                 ('num', 'passthrough',\n",
       "                                                  ['4', '66', '67'])])),\n",
       "                ('classifier',\n",
       "                 RFECV(estimator=DecisionTreeClassifier(random_state=0),\n",
       "                       n_jobs=-1, scoring=make_scorer(f1_score, average=macro),\n",
       "                       verbose=3))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OneHotEncoder\n",
    "categorical_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "#DecisionTreeClassifier\n",
    "Dtc = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "#Scorer to measure the performance of the estimators.\n",
    "scorer = make_scorer(f1_score,average='macro')\n",
    "\n",
    "#ColumnTransformer encodes categorical data with the categorical_encoder.\n",
    "#and numeric columns are not edited.\n",
    "preprocessing = ColumnTransformer(\n",
    "    [('cat', categorical_encoder, categorical_columns),\n",
    "     ('num', 'passthrough', numerical_columns)])\n",
    "\n",
    "\n",
    "\n",
    "#Created Pipeline to combine preprocessing of the data and the RFECV.\n",
    "#RFECV eliminates features recursively so that the useful features for the models remain.\n",
    "rfcv = Pipeline([\n",
    "    ('preprocess', preprocessing),\n",
    "    ('classifier',RFECV(estimator=Dtc,scoring=scorer,n_jobs=-1,verbose=3))\n",
    "])\n",
    "\n",
    "rfcv.fit(train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Female', 'Male'], dtype=object),\n",
       " array(['Both Sides', 'Left', 'Right'], dtype=object),\n",
       " array(['No', 'children', 'parents', 'parents|children',\n",
       "        'parents|siblings', 'siblings'], dtype=object),\n",
       " array(['Abrupt', 'Gradual'], dtype=object),\n",
       " array(['change in hearing', 'head trauma', 'loud blast of sound', 'other',\n",
       "        'stress', 'whiplash'], dtype=object),\n",
       " array(['NO', 'YES with heart beat', 'YES, different from heart beat'],\n",
       "       dtype=object),\n",
       " array(['both ears, equally', 'both ears, worse in left',\n",
       "        'both ears, worse in right', 'elsewhere', 'inside the head',\n",
       "        'left ear', 'right ear'], dtype=object),\n",
       " array(['No', 'Yes'], dtype=object),\n",
       " array(['crickets', 'noise', 'other', 'tone'], dtype=object),\n",
       " array(['high frequency', 'low frequency', 'medium frequency',\n",
       "        'very high frequency'], dtype=object),\n",
       " array(['2 - 4', '5 and more', 'none', 'one'], dtype=object),\n",
       " array(['I don’t know', 'NO', 'YES'], dtype=object),\n",
       " array(['I don’t know', 'NO', 'YES'], dtype=object),\n",
       " array(['NO', 'YES'], dtype=object),\n",
       " array(['has no effect', 'reduces my tinnitus', 'worsens my tinnitus'],\n",
       "       dtype=object),\n",
       " array(['I don’t know', 'NO', 'YES'], dtype=object),\n",
       " array(['has no effect', 'reduces my tinnitus', 'worsens my tinnitus'],\n",
       "       dtype=object),\n",
       " array(['NO', 'YES'], dtype=object),\n",
       " array(['Both', 'Left', 'None', 'Right'], dtype=object),\n",
       " array(['Always', 'Never', 'Rarely', 'Sometimes', 'Usually'], dtype=object),\n",
       " array(['I don’t know', 'NO', 'YES'], dtype=object),\n",
       " array(['NO', 'YES'], dtype=object),\n",
       " array(['NO', 'YES'], dtype=object),\n",
       " array(['NO', 'YES'], dtype=object),\n",
       " array(['NO', 'YES'], dtype=object),\n",
       " array(['NO', 'YES'], dtype=object),\n",
       " array(['NO', 'YES'], dtype=object)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get a boolean mask of the features which were selected by the RFECV.\n",
    "mask = rfcv.named_steps['classifier'].support_\n",
    "rfcv.named_steps['preprocess'].named_transformers_['cat'].categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty dataframe\n",
    "data = pd.DataFrame()\n",
    "\n",
    "#Get the one hot encoded column names.\n",
    "column_names= train2.columns\n",
    "\n",
    "#List which will be filled with  the column names of the features \n",
    "#which were selected by the RFECV and a target label\n",
    "Vals = ['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['5_Male', '8_No', '10_Abrupt', '11_stress', '35_both ears, equally',\n",
       "       '35_both ears, worse in left', '37_Yes', '40_tone', '68_2 - 4',\n",
       "       '68_none', '68_one', '70_NO', '71_YES', '72_worsens my tinnitus',\n",
       "       '74_has no effect', '76_YES', '78_Never', '78_Sometimes', '79_NO',\n",
       "       '80_YES', '83_YES', '4', '66', '67'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#iterate trough mask to get the selected features and write column names into data.\n",
    "for i in range(0,89):\n",
    "    if mask[i]==True:\n",
    "        data[column_names[i]]=train2.iloc[:,i]\n",
    "        \n",
    "data.columns       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write column names\n",
    "for i in range(0,len(data.columns)):\n",
    "    Vals.insert(i,data.columns[i].split('_')[0])\n",
    "\n",
    "#remove duplicates    \n",
    "Vals = list(dict.fromkeys(Vals))\n",
    "\n",
    "#filter the DataFrames so that only the column names from Vals are included.\n",
    "completed_train= completed_train.filter(items=Vals)                                  \n",
    "completed_validation= completed_validation.filter(items=Vals)\n",
    "completed_test= completed_test.filter(items=Vals)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test and Validation Data is written into different CSV.\n",
    "completed_train.to_csv(root+\"data/02_processed/completed_train.csv\",sep=';')\n",
    "completed_test.to_csv(root+\"data/02_processed/completed_test.csv\",sep=';')\n",
    "completed_validation.to_csv(root+\"data/02_processed/completed_validation.csv\",sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['5', '8', '10', '11', '35', '37', '40', '68', '70', '71', '72', '74',\n",
       "       '76', '78', '79', '80', '83', '4', '66', '67', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The Columns 6 13 65 69 73 77 81 82 84 85 are discarded because of RFECV.\n",
    "completed_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached\n"
     ]
    }
   ],
   "source": [
    "print('reached')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
